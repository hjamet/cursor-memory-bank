## TLDR
Adopte une posture de testeur critique. Ton but n'est pas de valider que √ßa fonctionne, mais de d√©couvrir *comment √ßa casse*. Cherche activement les failles et les points de rupture de l'impl√©mentation r√©cente.

## Purpose & Scope
L'√©tape `experience-execution` est con√ßue pour une **validation critique et manuelle**. L'objectif est de stresser l'impl√©mentation pour d√©couvrir ses faiblesses avant qu'elles n'atteignent l'utilisateur.

- **Chercher les points de rupture**: N'ex√©cute pas seulement le cas nominal. Essaie des entr√©es inattendues, des ordres d'ex√©cution inhabituels.
- **Valider la robustesse**: Que se passe-t-il en cas d'erreur ? Le syst√®me g√®re-t-il l'√©chec gracieusement ?
- **Identifier les effets de bord**: Ta modification a-t-elle eu un impact inattendu sur une autre partie du syst√®me ?

**Ce n'est PAS pour**:
- Des tests de complaisance (happy path testing).
- Valider uniquement que le code tourne sans erreur.

## When to Use Experience-Execution
This step is particularly valuable after:
- **Implementation steps**: To validate that the code you just wrote actually works
- **When tasks are in REVIEW**: To test implementations before user validation
- **After significant changes**: To ensure nothing broke during development
- **Before committing**: To avoid committing broken code

## Instructions

‚ö†Ô∏è **CRITICAL ANTI-LOOP PROTECTION**: When a test is **SUCCESSFUL**, you MUST follow this exact sequence to prevent infinite loops:
1. **FIRST**: Update task status to REVIEW using `mcp_MemoryBankMCP_update_task`
2. **SECOND**: Create commit using `mcp_MemoryBankMCP_commit`  
3. **THIRD**: Call remember using `mcp_MemoryBankMCP_remember`

**NEVER** skip step 1 or change this order. The workflow depends on this sequence for proper loop prevention.

1.  **Execute Manual Test**:
    - `<think>`
        - Comment puis-je mettre en √©chec cette impl√©mentation ?
        - Quel est le point le plus fragile de ce que je viens de coder ?
        - Que se passe-t-il si je fournis une entr√©e vide, invalide, ou si j'ex√©cute l'action deux fois ?
        - Quel est le test simple qui a le plus de chances de r√©v√©ler une faiblesse ?
    `</think>`
    - M√®ne un test critique. Exemples :
        - Running a command to test functionality
        - Interacting with a UI to verify behavior
        - Checking file contents or outputs
        - Testing API endpoints or interfaces
        - Executing the main use case for the feature
    - Clearly state whether the test was a **SUCCESS**, a **FAILURE**, or if you were **INTERRUPTED**.

2.  **Report Outcome & Next Steps**:

    - **If the test was a SUCCESS**:
        - `<think>`
            - Le test principal a r√©ussi, mais ai-je identifi√© des faiblesses ? Ma mission est de rapporter les probl√®mes.
            - Je dois marquer la t√¢che comme 'REVIEW' AVANT tout.
        `</think>`
        - **üö® MANDATORY FIRST STEP: Call `mcp_MemoryBankMCP_update_task` to set the status of the related task to `REVIEW`. This MUST be done before any other action.**
        - `<think>`
            - Now that the task is marked as REVIEW, I can proceed with the commit.
            - Formulate a clear and concise commit message that follows conventions. The message should summarize the changes that were just validated.
            - What is the correct emoji, type, title, and description for the commit?
        `</think>`
        - Call the `mcp_MemoryBankMCP_commit` tool with the composed message.
        - `<think>`
            - Now that the work is committed, I must evaluate if the changes were "drastic" to decide the next step.
            - A change is "drastic" if it involves:
                - Modifications to core architectural files (e.g., workflow rules, MCP server logic).
                - A large number of files being changed at once.
                - The completion of a major feature or epic.
            - Based on my last commit, were the changes drastic?
            - If YES, the next step should be `context-update` to ensure the project's context is fully synchronized.
            - If NO, and there are more tasks, the next step is `implementation`.
            - If NO, and there are no more tasks, `context-update` is still appropriate.
        `</think>`
        - **FINAL STEP: Call `mcp_MemoryBankMCP_remember`. N'utilise `user_message` que si tu as d√©couvert un probl√®me CRITIQUE qui n√©cessite l'attention imm√©diate de l'utilisateur.** La plupart du temps, ce champ doit √™tre vide.

    - **If the test was a FAILURE**:
        - `<think>`
            - Excellent, j'ai trouv√© une faille. Quelle est sa nature exacte ?
            - Quelle est la cause racine la plus probable ?
            - Comment puis-je d√©crire ce probl√®me de mani√®re claire et actionnable pour l'√©tape `fix` ?
        `</think>`
        - Call `mcp_MemoryBankMCP_remember` to document the failure and set the future step to `fix`. **Utilise l'argument `user_message` pour communiquer l'√©chec et son impact.** (ex: "√âchec critique du test : La nouvelle API de paiement autorise des transactions n√©gatives, ce qui pourrait entra√Æner des pertes financi√®res.").

    - **If you were INTERRUPTED**:
        - `<think>`
            - What was I trying to do when I was interrupted?
            - If I was trying to update a task's status (e.g., to 'APPROVED'), I should handle this to avoid a loop.
        `</think>`
        - If the interruption occurred during a task status update, change the task's status to **BLOCKED** using `mcp_MemoryBankMCP_update_task`. Add a comment explaining that the approval was interrupted by the user.
        - Call `mcp_MemoryBankMCP_remember` to document the interruption and set the future step to `context-update` to ensure the workflow can safely continue.

## Adversarial Mindset
Pense comme un attaquant ou un utilisateur maladroit.
- **Entr√©es invalides**: Que se passe-t-il avec `null`, `undefined`, des cha√Ænes vides, des nombres n√©gatifs ?
- **Double ex√©cution**: Si tu lances une commande deux fois de suite, est-ce que √ßa cr√©e un √©tat incoh√©rent ?
- **Conditions de course**: Y a-t-il un risque si deux processus acc√®dent √† la m√™me ressource ?
- **Gestion d'erreur**: Si une d√©pendance (ex: une API externe) √©choue, le syst√®me se comporte-t-il correctement ?

## Validation Strategies

### Code/Logic Changes
- Run the main functionality to ensure it works
- Test with typical inputs and check outputs
- Verify error handling with invalid inputs

### UI/Interface Changes  
- Load the interface and check for visual issues
- Test main user interactions
- Verify responsive behavior if applicable

### API/Service Changes
- Make test requests to new endpoints
- Verify response formats and status codes
- Check integration with existing systems

### Configuration/Setup Changes
- Test the configuration loads correctly
- Verify services start without errors
- Check that settings are applied properly

### File/Data Processing
- Process sample data through the new logic
- Verify output format and content
- Check error handling for malformed inputs

## Specifics
- This rule is for quick, targeted manual validation, not exhaustive testing.
- Focus on the main use case and obvious failure modes.
- The outcome must be a clear choice: SUCCESS, FAILURE, or INTERRUPTED.
- A commit is mandatory after a successful test.
- The `remember` tool is used to transition to the next logical step.
- **Remember**: You're validating that your implementation works, not building a comprehensive test suite.

## Next Steps
- `fix` - If the manual test failed.
- `implementation` - If the test was successful and the change was not drastic, and there are more tasks.
- `context-update` - If the test was successful and the change was drastic, or if no tasks are left, or if the process was interrupted.

## Example (Successful Test, Minor Change)

# Experience-Execution: 1 - Execute Manual Test
<think> I just implemented the JWT token generation in `auth.js`. I will run the associated test file `auth.test.js` to see if it passes and generates a token as expected. </think>
I will run the tests for the new authentication module.
`npm test -- src/auth/auth.test.js`
The test command finished successfully with all tests passing. The outcome is a **SUCCESS**.

# Experience-Execution: 2 - Report Outcome & Next Steps
<think>The test for task #42 succeeded. I MUST mark it as 'REVIEW' BEFORE doing anything else. ‚ö†Ô∏è CRITICAL: I must update the task status FIRST to prevent infinite loops.</think>
üö® MANDATORY FIRST STEP: I'm marking task #42 as REVIEW before proceeding with any other action.
[...calling `mcp_MemoryBankMCP_update_task` with task_id: 42, status: 'REVIEW'...]
<think> Now that the task is marked as REVIEW, I can proceed with the commit. A good commit message would be `feat(auth): Implement JWT generation`. I'll use the ‚ú® emoji. The description will detail the new endpoint. </think>
[...calling `mcp_MemoryBankMCP_commit` with emoji: '‚ú®', type: 'feat', title: 'feat(auth): Implement JWT generation', description: '- Added /login endpoint to generate JWT...']
<think> The commit was successful. This was a single-file change and not a core architectural modification. The change was not drastic. I see other tasks are pending. The next step should be `implementation`. </think>
FINAL STEP: Recording the successful test and determining next steps.
[...calling `mcp_MemoryBankMCP_remember` with PAST: "Successfully tested JWT generation", PRESENT: "Task marked as REVIEW, changes committed", FUTURE: "Proceed to the next task in `implementation`.", user_message: "Exp√©rience r√©ussie : Les tests pour la g√©n√©ration JWT sont tous pass√©s (12/12)." ...]

## Example (Successful Test, Drastic Change)

# Experience-Execution: 1 - Execute Manual Test
<think> I just refactored three workflow rules (`.md` files) to streamline the agent's decision-making. I will check the agent's memory to see if it correctly transitions between the new steps. </think>
I will check the agent's memory logs.
`cat .cursor/memory-bank/agent_memory.json`
The logs show the agent correctly followed the new workflow path. The outcome is a **SUCCESS**.

# Experience-Execution: 2 - Report Outcome & Next Steps
<think>The test for the workflow refactoring (task #43) succeeded. I MUST mark it as 'REVIEW' BEFORE doing anything else. ‚ö†Ô∏è CRITICAL: I must update the task status FIRST to prevent infinite loops.</think>
üö® MANDATORY FIRST STEP: I'm marking task #43 as REVIEW before proceeding with any other action.
[...calling `mcp_MemoryBankMCP_update_task` with task_id: 43, status: 'REVIEW'...]
<think> Now that the task is marked as REVIEW, I can proceed with the commit. The changes affected multiple core workflow files. This is a drastic architectural change. The commit message should reflect this. </think>
[...calling `mcp_MemoryBankMCP_commit` with emoji: '‚ôªÔ∏è', type: 'refactor', title: 'refactor(workflow): Streamline agent decision logic', description: '- Refactored experience-execution.md and implementation.md...']
<think> The commit was successful. Since this was a drastic change to the workflow, the correct next step is `context-update` to re-synchronize and re-evaluate the project state. </think>
FINAL STEP: Recording the successful test and determining next steps.
[...calling `mcp_MemoryBankMCP_remember` with PAST: "Successfully tested the refactored workflow", PRESENT: "Task marked as REVIEW, drastic changes committed", FUTURE: "Proceed to `context-update` for project re-synchronization.", user_message: "Exp√©rience r√©ussie : Le remaniement des r√®gles de workflow a √©t√© valid√©. L'agent suit correctement le nouveau flux."...]

## Example (Failed Test)

# Experience-Execution: 1 - Execute Manual Test
<think> I just refactored the database connection pool. I'll try to start the server, which should now connect to the database immediately. </think>
I will attempt to start the server.
`npm start`
The server failed to start, crashing with a `TimeoutError: could not connect to database`. The outcome is a **FAILURE**.

# Experience-Execution: 2 - Report Outcome & Next Steps
<think> The server can't connect to the database after my refactoring. It's likely an issue with the new connection string or pooling options. I need to investigate this in the `fix` step. </think>
[...calling `mcp_MemoryBankMCP_remember` with PAST: "Tested the new DB connection logic by starting the server.", PRESENT: "The server failed to start with a connection timeout.", FUTURE: "Switch to the `fix` workflow to debug the database connection.", user_message: "Exp√©rience √©chou√©e : Le serveur n'a pas pu d√©marrer et a retourn√© une erreur `TimeoutError: could not connect to database`."...]

# Experience-Execution: 1 - Execute Manual Test
<think> J'ai impl√©ment√© la g√©n√©ration de token JWT. Le cas nominal fonctionne. Essayons de casser quelque chose. Que se passe-t-il si je demande un token avec un payload vide ? </think>
Je vais tenter de g√©n√©rer un token JWT avec un payload vide.
`node -e "require('./src/auth').generateToken('')"`
La commande a crash√© avec une erreur `TypeError: payload must be a non-empty string`. C'est un **FAILURE**. Le syst√®me devrait g√©rer cette erreur gracieusement.

# Experience-Execution: 2 - Report Outcome & Next Steps
<think> Le test a √©chou√©. J'ai trouv√© une faille : le syst√®me ne g√®re pas les payloads vides. C'est une information cruciale pour l'√©tape `fix`. </think>
[...appel de `mcp_MemoryBankMCP_remember` avec PAST: "Test critique de la g√©n√©ration JWT.", PRESENT: "Le syst√®me crash avec un payload vide (TypeError). Il manque une validation d'entr√©e.", FUTURE: "Passer √† l'√©tape `fix` pour ajouter la validation.", user_message: "√âchec du test de robustesse sur la g√©n√©ration JWT : le syst√®me ne g√®re pas les entr√©es invalides et expose une erreur brute."...]
