---
description: Call this rule to execute unit tests and analyze the results
globs: 
alwaysApply: false
---

## TLDR
Execute unit tests, analyze results and document successes and failures in tests.md.

## Instructions

1. **Test execution**: Launch tests for implemented features
   - Capture all results (successes, failures, warnings)
   - Note precise error messages
   - After each tool call, write **(Test-execution - 1.[Test name] in progress...)**

2. **Results analysis**: Compare with previous tests
   - Read the `.cursor/memory-bank/workflow/tests.md` file if it exists
   - Identify improvements or regressions
   - After each tool call, write **(Test-execution - 2.[Analysis] in progress...)**

3. **Results documentation**: Update tests.md
   - Create file if necessary
   - Use format defined in tests-md editing rule
   - Include evolution analysis for each test
   - Document failures without conducting in-depth investigation

4. **Call next rule**
   - If at least one test improved without any regression → `context-update`
   - If no significant change → `context-update`
   - Otherwise, if at least one test regressed → `fix`

## Specifics

- Execute all available tests, not just new ones
- Do not attempt to fix errors (that's the role of the `fix` rule)
- An "improvement" means a previously failing test now passes or a warning is resolved
- A "regression" means a previously successful test now fails or generates a warning
- To avoid losing the workflow, systematically write **(Test-execution - [number].[Name] in progress...)** between each step
- ⚠️ **Command Execution Note**: The terminal tool occasionally exhibits a bug that adds "[200~" prefix and/or "~" suffix to commands (e.g., "[200~.venv/Scripts/python.exe" instead of ".venv/Scripts/python.exe"), resulting in "command not found" errors. These are NOT code or logic errors but tool-specific issues. If this occurs, simply retry the exact same command 2-3 times until it executes properly. Never treat these specific formatting errors as actual code problems or test failures.
- ⚠️ Similarly, if the command is put in the background, canceled, or interrupted by the user without any comment, it is certainly because the user has identified an execution problem related to the terminal. You must then relaunch the command as if nothing happened 2-3 times until it executes correctly. Do not consider these terminal tool bugs as actual code or test failure problems.
- Never skip calling the next rule

## Next Rules
- `fix` - If at least one test regressed
- `context-update` - If at least one test improved or no significant change (and no regression)

## Example

fetch_rules ["test-execution"]

# Test-execution: 1 - Test execution
I begin by executing the unit tests. **(Test-execution: 1 - Test execution)**
[...running the tests...]
I see that the command has been put in the background. It's certainly related to a simple terminal issue. I'm going to relaunch the command.
[...re-running the tests...]
**(Test-execution: 1 - Test execution)**

# Test-execution: 2 - Results analysis
I compare the results with previous tests. **(Test-execution: 2 - Results analysis)**
[...reading tests.md file...]
**(Test-execution - 2.Comparison in progress...)**
[...results comparison...]
**(Test-execution: 2 - Results analysis)**

# Test-execution: 3 - Results documentation
I update the tests.md file with new results. **(Test-execution: 3 - Results documentation)**
[...updating tests.md file...]
**(Test-execution: 3 - Results documentation)**

# Test-execution: 4 - Call next rule
I must now call the appropriate rule based on test results. **(Test-execution: 4 - Call next rule)**
[...analysis of improvements and regressions...]
I note that [description of test status changes]. I will therefore call the [fix/context-update] rule because we have two tests that have progressed and no regression. **(Test-execution: 4 - Call next rule)**

fetch_rules ["context-update"]

# Context-update: 1 - Context update
I begin by updating the context files to reflect changes. **(Context-update: 1 - Context update)**

[...] (The workflow must continue uninterrupted: the agent executes the following rule, then the next, etc., without ever stopping -> It is completely autonomous.)