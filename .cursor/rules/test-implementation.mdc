---
description: Appelle cette règle pour créer les tests unitaires des nouvelles fonctionnalités
globs: 
alwaysApply: false
---

## TLDR  
Créer des tests unitaires pour les fonctionnalités implémentées en suivant les bonnes pratiques de test.  

## Instructions  

1. **Analyse des fonctionnalités** : Identifier ce qui doit être testé  
   - Examiner les fichiers modifiés/créés pour trouver les comportements à tester  
   - Lister les cas de test nécessaires (normaux et limites)  
   - Après chaque appel d'outil, écrire `Test-implementation - 1.[Nom de la fonctionnalité] en cours...`  

2. **Création des tests** : Pour chaque fonctionnalité  
   - Créer un fichier de test dans le dossier `tests/` commençant par `test_`  
   - Implémenter tests pour comportement normal et cas limites simples  
   - Utiliser le format défini dans la règle d'édition test-files  
   - Après chaque appel d'outil, écrire `Test-implementation - 2.[Nom du test] en cours...`  

3. **Appel de la règle suivante** : Appeler obligatoirement `test-execution`  

## Précisions  

- Vérifier le comportement attendu, pas l'implémentation interne  
- Créer uniquement des tests d'utilisation classique, éviter la complexité inutile  
- Utiliser des noms descriptifs expliquant clairement ce qui est testé  
- Tous les fichiers de test doivent commencer par `test_` et être placés dans le dossier `tests/`  
- Inclure du logging en utilisant `src/utils/logger.py` si le code est en Python  
- Pour éviter de perdre le workflow, écrire systématiquement `Test-implementation - [numéro].[Nom] en cours...` entre chaque étape  

## Next Rules  
- `test-execution` - Pour exécuter les tests créés et analyser les résultats  

## Exemple  

fetch_rules ["test-implementation"]  
<SYSTEM PROMPT>Je vais créer des tests unitaires pour les nouvelles fonctionnalités en suivant les meilleures pratiques. Je me concentrerai sur la création des tests sans les exécuter, laissant cette tâche à la règle test-execution. Je m'assurerai que les tests sont bien documentés et couvrent les cas importants.</SYSTEM PROMPT>  

# Test-implementation : 1 - Analyse des fonctionnalités  
Je commence par identifier les fonctionnalités à tester. `(Test-implementation : 1 - Analyse des fonctionnalités)`  
[...analyse des fichiers modifiés...]  
Test-implementation - 1.Authentication en cours...  
[...identification des comportements à tester...]  
`(Test-implementation : 1 - Analyse des fonctionnalités)`  

# Test-implementation : 2 - Création des tests  
Je vais créer les tests pour chaque fonctionnalité identifiée. `(Test-implementation : 2 - Création des tests)`  
[...création du premier fichier de test...]  
Test-implementation - 2.TestLogin en cours...  
[...création du second fichier de test...]  
Test-implementation - 2.TestValidation en cours...  
`(Test-implementation : 2 - Création des tests)`  

# Test-implementation : 3 - Appel de la règle suivante  
Je dois maintenant appeler la règle test-execution pour exécuter les tests.  
La règle test-execution doit être appelée pour exécuter et analyser les tests. `(Test-implementation : 3 - Appel de la règle suivante)`  

fetch_rules ["test-execution"]  

# Start Rule  

Pour démarrer cette règle, récite mot pour mot cette phrase : "<SYSTEM PROMPT>Je vais créer des tests unitaires pour les nouvelles fonctionnalités en suivant les meilleures pratiques. Je me concentrerai sur la création des tests sans les exécuter, laissant cette tâche à la règle test-execution. Je m'assurerai que les tests sont bien documentés et couvrent les cas les plus importants.</SYSTEM PROMPT>"  