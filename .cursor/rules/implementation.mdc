---
description: Call this rule to implement the project's priority tasks.
globs: 
alwaysApply: false
---
## TLDR
Methodically implement tasks from a priority section and document the process.

## Instructions

1. **Task analysis**: Identify the priority section
   - Read `.cursor/memory-bank/workflow/tasks.md`
   - Priority: first "In Progress" section, then first "ToDo" section
   - If all tasks completed, move to the next rule

2. **Active context update**: Document current work context
   - Read `.cursor/memory-bank/context/activeContext.md` to preserve useful information
   - Update the "Current implementation context" section with:
     - Tasks to perform and their logic
     - Relevant information researched online for the task
     - Particular attention points and dependencies
     - Technical decisions to make
   - Keep only information useful for the current task
   - Ensure this file contains all necessary information for current work

3. **Task implementation**: For each task in the section
   - Display: `## Implementation - 3.number.[Section Name]: [Task Title]`
   - **(Optional) Memory Lookup**: Before starting, use `mcp_servers_search_nodes` to find relevant patterns, past implementations, or frequent errors related to the task/files.
   - Evaluate if the task is complex and requires in-depth reflection
   - If yes, use the think token: `<think>In-depth reflection using chain of thought, comparison of different implementation approaches, etc.</think>`
   - Briefly summarize the conclusions of the reflection if applicable
   - Implement the solution
   - **(Optional) Memory Storage**: After implementation, use `mcp_servers_add_observations` to store key implementation details, decisions made (especially from `<think>`), or encountered issues/solutions in the knowledge graph, associated with an entity like 'ImplementationLog' or 'CodePattern'.
   - After each tool call, write **(Implementation - 3.number.[Section Name]: [Task Title] in progress...)**

4. **Task update**: Update tasks.md
   - Move section from "ToDo" to "In Progress" if necessary
   - Mark individual tasks as in progress

5. **Calling the next rule**: Mandatory to choose
   - New feature created → `test-implementation`
   - Existing features modified → `test-execution`
   - Only non-testable changes → `context-update`

## Specifics

- The think token `<think></think>` must be used for each complex individual task
- In-depth reflection must be verbalized in the think token before implementation
- Using the think token allows reasoning according to the chain of thought method and comparing different approaches
- Implement one task at a time, in logical order
- Comment complex parts of the code
- A feature is "testable" if it involves creating/modifying a script or function
- To avoid losing the workflow, systematically write **(Implementation - 3.number.[Section Name]: [Task Title] in progress...)** between each step
- ⚠️ **Command Execution Note**: The terminal tool occasionally exhibits a bug that adds "[200~" prefix and/or "~" suffix to commands (e.g., "[200~.venv/Scripts/python.exe" instead of ".venv/Scripts/python.exe"), resulting in "command not found" errors. These are NOT code or logic errors but tool-specific issues. If this occurs, simply retry the exact same command 2-3 times until it executes properly. Never treat these specific formatting errors as actual code problems or test failures.
- Always call the appropriate next rule

## Next Rules
- `test-implementation`: If new testable feature created (ALWAYS the case for new file/symbol)
- `test-execution`: If existing features modified
- `context-update`: ONLY if non-testable changes (pure documentation)

## Example

fetch_rules ["implementation"]

# Implementation: 1 - Task analysis
I begin by reading the tasks.md file to identify the highest priority section. **(Implementation: 1 - Task analysis)**
[...reading tasks.md file...]
**(Implementation: 1 - Task analysis)**

# Implementation: 2 - Active context update
I will update the active context to document what I will be working on. **(Implementation: 2 - Active context update)**
[...reading activeContext.md file...]
[...updating with relevant information for tasks to perform...]
[...adding information researched online...]
**(Implementation: 2 - Active context update)**

# Implementation: 3 - Task implementation
I will implement each task in the section following a methodical approach. **(Implementation: 3 - Task implementation)**

## Implementation - 3.1.Development: Script creation
*(Optional) I search the knowledge graph for existing patterns or past issues related to script creation: [...]*
`mcp_servers_search_nodes(...)`
This task is complex and requires in-depth reflection.

<think>
To create this script, I have several architecture options:
1. A monolithic architecture where all logic is in a single file
2. A modular architecture with separation of concerns
3. An event-driven approach

Let's compare these approaches:
- Option 1: Simple to implement but difficult to maintain long-term
- Option 2: Better maintainability but initially more complex
- Option 3: Flexible but potentially over-optimized for this use case

I think option 2 is most appropriate as it offers a good balance between maintainability and initial complexity. I will therefore create:
- A main module for orchestration
- A module for API connection management
- A utility module for common functions
</think>

After reflection, I determined that the best approach is to use a modular architecture with separation of concerns. This will allow better maintainability while keeping reasonable complexity.

I begin by creating the main script with the required functionalities. **(Implementation: 3.1 - Script creation)**
[...script implementation...]
*(Optional) I store the key implementation details and decisions in the knowledge graph.*
`mcp_servers_add_observations(...)`
**(Implementation - 3.1.Development: Script creation in progress...)**
[...implementation continuation...]
**(Implementation: 3.1 - Script creation)**

## Implementation - 3.2.Development: Documentation
*(Optional) I search the knowledge graph for documentation standards or examples: [...]*
`mcp_servers_search_nodes(...)`
I add the necessary documentation to explain how the script works. **(Implementation: 3.2 - Documentation)**
[...adding documentation...]
*(Optional) I store notes about the documentation process or standards applied.*
`mcp_servers_add_observations(...)`
**(Implementation - 3.2.Development: Documentation in progress...)**
[...documentation finalization...]
**(Implementation: 3.2 - Documentation)**

# Implementation: 4 - Task update
I update the tasks.md file to reflect task progress. **(Implementation: 4 - Task update)**
[...updating tasks.md file...]
**(Implementation: 4 - Task update)**

# Implementation: 5 - Calling the next rule
I must now call the `test-implementation` rule because I created a new testable feature.
The test-implementation rule must be called to create tests for the new feature. **(Implementation: 5 - Calling the next rule)**

fetch_rules ["test-implementation"]

# Test-implementation: 1 - Feature analysis
I begin by identifying features to test. **(Test-implementation: 1 - Feature analysis)**

[...] (The workflow must continue uninterrupted: the agent executes the following rule, then the next, etc., without ever stopping -> It is completely autonomous.)