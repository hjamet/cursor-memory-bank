---
description: Rule to consolidate the repository, manage userbrief.md, and maintain a clean project structure
globs: 
alwaysApply: false
---
## TLDR
Repository consolidation, transformation of user requests into tasks, cleaning userbrief.md, and verification of memory files integrity.

## Repository Structure (for reference)
```
.cursor/memory-bank/  
â”œâ”€â”€ context/                 # Project context  
â”‚   â”œâ”€â”€ projectBrief.md      # Project global vision  
â”‚   â”œâ”€â”€ activeContext.md     # Current work context  
â”‚   â””â”€â”€ techContext.md       # Technologies and dependencies  
â”œâ”€â”€ workflow/                # Workflow management  
â”‚   â”œâ”€â”€ tasks.md             # List of tasks to accomplish
â”‚   â””â”€â”€ tests.md             # Test results tracking
src/                         # Project source scripts  
tests/                       # Unit and integration tests  
```

## Instructions

1. **Processing userbrief.md**: Analyze and transform content:
   - Read content from "User Input" section in `.cursor/memory-bank/userbrief.md`
   - Identify content type: tasks or preferences
   - For tasks: mark with ðŸ”„ and move to "Processing"
   - For preferences: mark with ðŸ“Œ and move to "Precisions"
   - Don't convert tasks for tasks.md yet (this will be done by task-decomposition)

2. **Organizing userbrief.md**: Structure content according to template:
   - Maintain 3 main sections: "User Input", "Processing", "Precisions"
   - Apply appropriate statuses:
     - â¬œ : To be processed
     - ðŸ”„ : In progress (for tasks only)
     - ðŸ“Œ : Long-term preference
     - âœ… : Completed (not to be used, left for task-decomposition)
   - Ensure structure remains clear and readable

3. **Integrity verification**: Control of memory files:
   - Execute command `find . -type f -name "*.md"` to list all markdown files
   - Analyze results to find duplicates in memory-bank directories
   - Merge content of duplicate files with main files
   - Delete duplicates after merging (use `rm` command for this and not the `file delete` tool)
   - Verify all memory files are in the right place

4. **Cleanup task identification**: Generate tasks for tasks.md:
   - Identify unnecessary temporary files
   - Locate misplaced files
   - List necessary cleanup actions
   - Add these tasks to `.cursor/memory-bank/workflow/tasks.md` (without executing them directly)

5. **Evaluation of user requests**: Decide next workflow step:
   - If new requests identified in userbrief.md:
     - Clearly formulate user request extracted from userbrief.md
     - Call `request-analysis` rule to process this request
   - Otherwise:
     - Call `context-update` rule to continue workflow

## Specifics

- Content of `.cursor/memory-bank/userbrief.md` must never be deleted without explicit user authorization
- Only structure and organization can be modified
- User requests must always be processed with priority
- Duplicates must be carefully merged to lose no information
- Files to be deleted should be deleted only after merging and using the `rm` command in the terminal and not the `file delete` tool (because of a bug in the tool)
- This rule should only be called by context-update when structure problems are detected
- IMPORTANT: Only this rule is authorized to modify userbrief.md
- IMPORTANT: Mark tasks with ðŸ”„ (only) and preferences with ðŸ“Œ
- IMPORTANT: Never use âœ…, this is reserved for task-decomposition
- âš ï¸ **Command Execution Note**: The terminal tool occasionally exhibits a bug that adds "[200~" prefix and/or "~" suffix to commands (e.g., "[200~.venv/Scripts/python.exe" instead of ".venv/Scripts/python.exe"), resulting in "command not found" errors. These are NOT code or logic errors but tool-specific issues. If this occurs, simply retry the exact same command 2-3 times until it executes properly. Never treat these specific formatting errors as actual code problems or test failures.

## Next Rules

- `request-analysis` - If new requests identified in userbrief.md
- `context-update` - If no new request identified

## Example

fetch_rules ["consolidate-repo"]

# Consolidate-repo: 1 - Processing userbrief.md
I begin by analyzing the content of `.cursor/memory-bank/userbrief.md`. (Consolidate-repo: 1 - Processing userbrief.md)
[...reading and analyzing userbrief.md content...]
I've identified several user requests that I will mark as follows:
- Tasks to perform: ðŸ”„ (moving to "Processing")
- Long-term preferences: ðŸ“Œ (moving to "Precisions")
(Consolidate-repo: 1 - Processing userbrief.md)

# Consolidate-repo: 2 - Organizing userbrief.md
I'm now reorganizing the content of .cursor/memory-bank/userbrief.md according to the 3-section structure. **(Consolidate-repo: 2 - Organizing userbrief.md)**
[...content reorganization...]
I've applied appropriate statuses to the different elements. **(Consolidate-repo: 2 - Organizing userbrief.md)**

# Consolidate-repo: 3 - Integrity verification
I'm now verifying the integrity of memory files. **(Consolidate-repo: 3 - Integrity verification)**
find . -type f -name "*.md"
[...analyzing command results...]
I've identified some duplicates that I've merged with main files. **(Consolidate-repo: 3 - Integrity verification)**

# Consolidate-repo: 4 - Cleanup task identification
I'm now identifying necessary cleanup tasks. **(Consolidate-repo: 4 - Cleanup task identification)**
[...task identification...]
I've added these tasks to `.cursor/memory-bank/workflow/tasks.md` for later validation. **(Consolidate-repo: 4 - Cleanup task identification)**

# Consolidate-repo: 5 - Evaluation of user requests
I'm now evaluating if I've identified new user requests. **(Consolidate-repo: 5 - Evaluation of user requests)**
I found the following requests in the userbrief.md file:
- [Summary of extracted requests]

I will now call the request-analysis rule to process these requests. **(Consolidate-repo: 5 - Evaluation of user requests)**

fetch_rules ["request-analysis"]

# Request-analysis: 1 - Request analysis
I begin by analyzing the user's request to properly understand their demand. **(Request-analysis: 1 - Request analysis)**

[...] (The workflow must continue uninterrupted: the agent executes the following rule, then the next, etc., without ever stopping -> It is completely autonomous.)